<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>TREC 2023 Product Search Track</title>
    <meta name="generator" content="Jekyll v3.9.2" />
    <meta property="og:title" content="TREC 2023 Product Search Track" />
    <meta property="og:locale" content="en_US" />
    <meta name="description" content="website for TREC 2023 Product Search Track" />
    <meta property="og:description" content="website for TREC 2023 Product Search Track" />
    <link rel="canonical" href="https://trec-product-search.github.io/index.html" />
    <meta property="og:url" content="https://trec-product-search.github.io/index.html" />
    <meta property="og:site_name" content="trec product search" />
    <meta property="og:type" content="website" />
    <meta property="twitter:title" content=" TREC 2023 Product Search Track"" />
    <link rel="stylesheet" href="assets/css/style.css">
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-K8N7CE1L36"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-K8N7CE1L36');
    </script>
    <link href="//cdn-images.mailchimp.com/embedcode/classic-071822.css" rel="stylesheet" type="text/css">
    <style type="text/css">
	  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif;  width:600px;}
    </style>
  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      <h1>End To End Product Retrieval</h1>
      <!--<p><strong>Dataset paper:</strong> <a href="">Coming Soon</a></p> -->
      <h2 id="coordinators">Coordinators</h2>
      <p><a href='https://spacemanidol.com/'>Daniel Campos (University of Illinois)</a>, <a href='https://twitter.com/kallumadi?lang=en'> Surya Kallumadi(Lowes)</a>, <a href='http://corbyrosset.com/' >Corby Rosset (Microsoft)</a>, <a href='http://czhai.cs.illinois.edu/'>ChengXiang Zhai (University of Illinois)</a>, <a href='https://www.linkedin.com/in/alemagnani/'>Alessandro Magnani (Walmart)</a></p>
      <p>For any questions, comments, or suggestions please <a href="mailto:dcampos3@illinois.edu">email Daniel Campos</a> or sign up for email updates</p>
      <div id="mc_embed_signup">
          <form action="https://github.us21.list-manage.com/subscribe/post?u=e4f0c0ae69016a1dc61978146&amp;id=a8af48cfa8&amp;f_id=00a598e1f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
            <div id="mc_embed_signup_scroll">
              <h2>Subscribe For TREC Product Search Updates</h2>
              <div class="indicates-required"><span class="asterisk">*</span> indicates required</div>
              <div class="mc-field-group">
                <label for="mce-EMAIL">Email Address  <span class="asterisk">*</span></label>
                <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" required>
                <span id="mce-EMAIL-HELPERTEXT" class="helper_text"></span>
              </div>
              <div id="mce-responses" class="clear foot">
                <div class="response" id="mce-error-response" style="display:none"></div>
                <div class="response" id="mce-success-response" style="display:none"></div>
              </div>
              <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_e4f0c0ae69016a1dc61978146_a8af48cfa8" tabindex="-1" value=""></div>
              <div class="optionalParent">
                <div class="clear foot">
                  <input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button">
                  <p class="brandingLogo"><a href="http://eepurl.com/iprH0A" title="Mailchimp - email marketing made easy and fun"><img src="https://eep.io/mc-cdn-images/template_images/branding_logo_text_dark_dtp.svg"></a></p>
                </div>
              </div>
            </div>
          </form>
      </div>
      <script type='text/javascript' src='//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js'></script><script type='text/javascript'>(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='ADDRESS';ftypes[3]='address';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';}(jQuery));var $mcj = jQuery.noConflict(true);</script>                                                                  
      <h2 id="timetable">Timetable</h2>
      <ul>
        <li>May 1st: 2023 queries released to participants for all tasks</li>
	<li>July 31st: Submissions open for all tasks</li>
        <li>August 10st: Submissions close for all tasks</li>
        <li>November 12-14th: TREC conference</li>
      </ul>
      <h2 id="introduction">Introduction</h2>
      <p>The Product Search Track studies information retrieval in the field of product search. This is the case where there is a corpus of many products where the user goal and intent is to find the product that suits their need. </p>
      <p>Our main goal is to study what how end to end retrieval systems can be built and evaluated given a large set of products.</p>
      <h2 id="track-tasks">Track Tasks</h2>
      <p>The product search track has three tasks: ranking, end to end retrieval and multi modal end to end retrieval. You can submit up to three runs for each of these tasks.</p>
      <p>Each track uses the same training data originating from the <a href='https://amazonkddcup.github.io/'>ESCI Challenge for Improving Product Search</a> and shares the same set of evaluation queries. </p>
      <p>Below the three tasks are described in more detail.</p>
      <h3 id="ranking">Product Ranking Task</h3>
      <p>The first task focuses on product ranking. In task we provide an initial ranking of 1000 documents from a BM25 baseline and you are expected to re-rank the products in terms of their relevance to the users given intent. </p>
      <p>The ranking provides a focused task where the candidate sets are fixed and there is no need to implement complex end to end systems which makes experimentation quick and runs easily comparable.</p>
      <h3 id="retrieval">Product Retrieval Task</h3>
      <p>The second task focuses on end to end product retrieval. In task we provide an a large collection of products and participants need to design end to end retrieval systems which leverage whichever information they find relevant/useful.</p>
      <p>Unlike the ranking task, the focus here is in understanding the interplay between retrieval and reranking systems.</p>
      <h3 id="retrieval">Multi-Modal Product Retrieval Task</h3>
      <p>The third task focuses on end to end product retrieval using multiple modalities. In task we provide an a large collection of products where each product features additional attributes and information such as related clicks and images and participants need to design end to end retrieval systems which leverage whichever information they find relevant/useful.</p>
      <p>The focus of this task is to understand the interplay between different modalities and the value which additional potentially weak data provides.</p>
      <h3 id="use-of-external-information">Use of external information</h3>
      <p>You are allowed to use external information while developing your runs. When you submit your runs, please fill in a form listing what evidence you used, for example an external corpus such as Wikipedia or a pre-trained model or some proprietary corpus.</p>
      <p>When submitting runs, participants will be able to indicate what resources they used. This will allow us to analyze the runs and break they down into types.</p>
      <h3 id="datasets">Datasets</h3>
      <p>As mentioned above, each of the tasks share training data and test queries so there is only one dataset provided below</p>
      <p>All datasets can be found on Hugginface under the organization of <a href='https://huggingface.co/trec-product-search'>TREC Product Search</a>
      <table>
        <thead>
          <tr>
            <th>Type</th>
            <th>Filename</th>
            <th style="text-align: right">File size</th>
            <th style="text-align: right">Num Records</th>
            <th style="text-align: right">Description</th>
            <th>Format</th>
          </tr>
        </thead>
        <tbody>
	  <tr>
            <td>Query to Query ID</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Corpus-v0.1/resolve/main/data/qid2query.tsv">Query2QueryID </a></td>
            <td style="text-align: right">946 KB</td>
            <td style="text-align: right">30,734</td>
            <td style="text-align: right">TREC style QueryID to Query Text</td>
            <td>tsv: qid\tquery</td>
          </tr>					 
          <tr>
            <td>Collection</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Corpus-v0.1/resolve/main/data/trec/collection.trec.gz">Collection (TREC Format)</a</td>
            <td style="text-align: right">1.81 GB (568 MB compressed)</td>
            <td style="text-align: right">1,661,907</td>
            <td style="text-align: right">TREC style corpus collection</td>
            <td>tsv: docid\tTitle\tDescription</td>
          </tr>
	  <tr>
            <td>Collection</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Corpus-v0.1/resolve/main/data/pyserini-simple/collection.jsonl.gz">Collection (Pyserini- Simplified)</a</td>
            <td style="text-align: right">1.9 GB (573.2 MB compressed)</td>
            <td style="text-align: right">1,661,907</td>
            <td style="text-align: right">Pyserini Style Simple JSONL corpus collection</td>
            <td>json: docid, contents (Title and Description) </td>
          </tr>
	  <tr>
            <td>Collection</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Corpus-v0.1/resolve/main/data/pyserini-simple/collection.parqueet.gz">Collection (Pyserini- Simplified) Parquet</a</td>
            <td style="text-align: right">900.3 MB (770.9 MB compressed)</td>
            <td style="text-align: right">1,661,907</td>
            <td style="text-align: right">Pyserini Style Simple Parqueet corpus collection</td>
            <td>json: docid, contents (Title and Description) </td>
          </tr>	
	  <tr>
            <td>Collection</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Corpus-v0.1/resolve/main/data/pyserini-full/collection.jsonl.gz">Collection (Pyserini- Full)</a</td>
            <td style="text-align: right">10.69 GB (2.8 GB compressed)</td>
            <td style="text-align: right">1,661,907</td>
            <td style="text-align: right">Pyserini Style Full JSONL corpus collection</td>
            <td>json: docid, contents (Title,Description, metadata, reviews) </td>
          </tr>
	  <tr>
            <td>Collection</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Corpus-v0.1/resolve/main/data/pyserini-full/collection.parqueet.gz">Collection (Pyserini- Full) Parquet</a</td>
            <td style="text-align: right">4.56 GB (3.92 GB compressed)</td>
            <td style="text-align: right">1,661,907</td>
            <td style="text-align: right">Pyserini Style Full Parqueet corpus collection</td>
            <td>json: docid, contents (Title,Description, metadata, reviews) </td>
          </tr>
	  <tr>
            <td>Collection</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Corpus-v0.1/resolve/main/data/jsonl/collection.json.gz">Collection JSONL</a</td>
            <td style="text-align: right">10.3 GB (2.78 GB compressed)</td>
            <td style="text-align: right">1,661,907</td>
            <td style="text-align: right">JSONL Collection/td>
            <td>json: docid, contents (Title,Description, metadata, reviews) </td>
          </tr>	
	  <tr>
            <td>Collection</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Corpus-v0.1/resolve/main/data/jsonl/collection.parquet.gz">Collection Parquet</a</td>
            <td style="text-align: right">5.22 GB (4.53 GB compressed)</td>
            <td style="text-align: right">1,661,907</td>
            <td style="text-align: right">JSONL Collection (Parquet)/td>
            <td>json: docid, contents (Title,Description, metadata, reviews) </td>
          </tr>	
          <tr>
            <td>Train QREL</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/blob/main/data/train/product-search-train.qrels.gz">Train QRELS (TREC Format)</a</td>
            <td style="text-align: right">6.8 MB (2.1 MB compressed)</td>
            <td style="text-align: right">392,119</td>
            <td style="text-align: right">Train QRELs/td>
            <td>tsv: qid,0, docid, relevance label </td>
          </tr>
	  <tr>
            <td>Train QREL (JSON)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/train/product-search-train-qrels.jsonl.gz">Train QRELS (JSONL Format)</a</td>
            <td style="text-align: right">21.5 MB (2.4 MB compressed)</td>
            <td style="text-align: right">392,119</td>
            <td style="text-align: right">Train QRELs (JSON)/td>
            <td>json: qid,0, docid, relevance label </td>
          </tr>	
	  <tr>
            <td>Train QREL (Parquet)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/train/product-search-train-qrels.parquet.gz">Train QRELS (Parquet Format)</a</td>
            <td style="text-align: right">2.4 MB (2 MB compressed)</td>
            <td style="text-align: right">392,119</td>
            <td style="text-align: right">Train QRELs (Parquet)/td>
            <td>json: qid,0, docid, relevance label </td>
          </tr>					
	  <tr>
            <td>Dev QREL</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/blob/main/data/dev/product-search-dev.qrels.gz">Dev QRELS (TREC Format)</a</td>
            <td style="text-align: right">2.9 MB (906 KB compressed)</td>
            <td style="text-align: right">169,952</td>
            <td style="text-align: right">Dev QRELs/td>
            <td>tsv: qid,0, docid, relevance label </td>
          </tr>
	  <tr>
            <td>Dev QREL (JSON)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/dev/product-search-dev-qrels.jsonl.gz">Dev QRELS (JSONL Format)</a</td>
            <td style="text-align: right">21.5 MB (2.4 MB compressed)</td>
            <td style="text-align: right">169,952</td>
            <td style="text-align: right">Dev QRELs (JSON)/td>
            <td>json: qid,0, docid, relevance label </td>
          </tr>	
	  <tr>
            <td>Dev QREL (Parquet)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/dev/product-search-dev-qrels.parquet.gz">Dev QRELS (Parquet Format)</a</td>
            <td style="text-align: right">2.4 MB (2 MB compressed)</td>
            <td style="text-align: right">169,952</td>
            <td style="text-align: right">Dev QRELs (Parquet)/td>
            <td>json: qid,0, docid, relevance label </td>
          </tr>
	  <tr>
            <td> 2023 Test Queries</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/test/2023-test-queries.tsv.gz">Dev QRELS (TREC Format)</a</td>
            <td style="text-align: right">52 KB (28 KB compressed)</td>
            <td style="text-align: right">926</td>
            <td style="text-align: right">2023 Test Queriestd>
            <td>tsv: qid,query text </td>
          </tr>
	  <tr>
            <td>Test QREL</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/blob/main/data/test/product-search-test.qrels.gz">Test QRELS (TREC Format)</a</td>
            <td style="text-align: right">18kb (6 KB compressed)</td>
            <td style="text-align: right">998</td>
            <td style="text-align: right">Test QRELs (Recal BaseD)/td>
            <td>tsv: qid,0, docid, relevance label </td>
          </tr>
	  <tr>
            <td>Test QREL (JSON)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/test/product-search-test-qrels.jsonl.gz">Test QRELS (JSONL Format)</a</td>
            <td style="text-align: right">15kb (7 KB compressed)</td>
            <td style="text-align: right">998</td>
            <td style="text-align: right">Test QRELs (JSON)/td>
            <td>json: qid,0, docid, relevance label </td>
          </tr>	
	  <tr>
            <td>Test QREL (Parquet)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/test/product-search-test-qrels.parquet.gz">Test QRELS (Parquet Format)</a</td>
            <td style="text-align: right">13kb (7 KB compressed)</td>
            <td style="text-align: right">998</td>
            <td style="text-align: right">Test QRELs (Parquet)/td>
            <td>json: qid,0, docid, relevance label </td>
          </tr>	
	  <tr>
            <td>Triples</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Triples/resolve/main/train.jsonl.gz">Train Triples JSONl</a></td>
            <td style="text-align: right">6.23 GB (1.28 GB compressed)</td>
            <td style="text-align: right">20,888</td>
            <td style="text-align: right">Training Triples json format</td>
            <td>json: qid, query, positive passages, negative passages</td>
          </tr>
	  <tr>
            <td>Triples</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Triples/resolve/main/train.jsonl.gz">Train Triples JSONl</a></td>
            <td style="text-align: right">6.23 GB (1.28 GB compressed)</td>
            <td style="text-align: right">20,888</td>
            <td style="text-align: right">Training Triples json format</td>
            <td>json: qid, query, positive passages, negative passages</td>
          </tr>				
	  <tr>
            <td>Triples</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Triples/resolve/main/dev.jsonl.gz">Dev Triples JSONl</a></td>
            <td style="text-align: right">2.67 GB (550.3 MB compressed)</td>
            <td style="text-align: right">8,956</td>
            <td style="text-align: right">Development Triples json format</td>
            <td>tsv: qid, query</td>
          </tr>	
	  <tr>
            <td>Triples</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Triples/resolve/main/dev.parquet.gz">Dev Triples PARQUET</a></td>
            <td style="text-align: right">938 MB (777.2 MB compressed)</td>
            <td style="text-align: right">8,956</td>
            <td style="text-align: right">Development Triples parquet format</td>
            <td>tsv: qid, query</td>
          </tr>	
	  <tr>
            <td>Triples</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Triples/resolve/main/test.parquet.gz">Test Triples PARQUET</a></td>
            <td style="text-align: right">47 KB (37 KB compressed)</td>
            <td style="text-align: right">926</td>
            <td style="text-align: right">Test Triples parquet format</td>
            <td>tsv: qid, query</td>
          </tr>					 
	   <tr>
            <td>Triples</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Triples/resolve/main/test.json.gz">Test Triples JSON</a></td>
            <td style="text-align: right">125 KB (30 KB compressed)</td>
            <td style="text-align: right">926</td>
            <td style="text-align: right">Test Triples json format</td>
            <td>tsv: qid, query</td>
          </tr>	
	  <tr>
            <td>Train Top 100 BM25 (Pyserini Simple Context)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/train/pyserini-simple-train-2023.run.gz">Top 100 Train BM25 Simple</a></td>
            <td style="text-align: right">107.3 MB (28.8 MB compressed)</td>
            <td style="text-align: right">2,046,828</td>
            <td style="text-align: right">BM25 top 100 For Train Queries</td>
            <td>tsv: qid, doc_id, rank, score, run-name</td>
          </tr>
	  <tr>
            <td>Train Top 100 BM25 (Pyserini Full Context)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/train/pyserini-full-train-2023.run.gz">Top 100 Train BM25 Simple</a></td>
            <td style="text-align: right">103.7 MB (28.8 MB compressed)</td>
            <td style="text-align: right">2,055,876</td>
            <td style="text-align: right">BM25 top 100 For Train Queries</td>
            <td>tsv: qid, doc_id, rank, score, run-name</td>
          </tr>
	  <tr>
            <td>Dev Top 1000 BM25 (Pyserini Simple Context)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/dev/pyserini-simple-dev-2023.run.gz">Top 100 Dev BM25 Simple</a></td>
            <td style="text-align: right">107.3 MB (28.8 MB compressed)</td>
            <td style="text-align: right">8,717,672</td>
            <td style="text-align: right">BM25 top 1000 For Dev Queries</td>
            <td>tsv: qid, doc_id, rank, score, run-name</td>
          </tr>
	  <tr>
            <td>Dev Top 1000 BM25 (Pyserini Full Context)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/dev/pyserini-full-dev-2023.run.gz">Top 100 Dev BM25 Simple</a></td>
            <td style="text-align: right"> 447.4 MB (121.1 MB compressed)</td>
            <td style="text-align: right">8,717,672</td>
            <td style="text-align: right">BM25 top 1000 For Dev Queries</td>
            <td>tsv: qid, doc_id, rank, score, run-name</td>
          </tr>
	  <tr>
            <td>Test Top 1000 BM25 (Pyserini Simple Context)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/test/pyserini-simple-test-2023.run.gz">Top 100 Test BM25 Simple</a></td>
            <td style="text-align: right">4.1 MB (1.1 MB compressed)</td>
            <td style="text-align: right">75,452</td>
            <td style="text-align: right">BM25 top 1000 For Test Queries</td>
            <td>tsv: qid, doc_id, rank, score, run-name</td>
          </tr>
	  <tr>
            <td>Dev Top 1000 BM25 (Pyserini Full Context)</td>
            <td><a href="https://huggingface.co/datasets/trec-product-search/Product-Search-Qrels-v0.1/resolve/main/data/test/pyserini-full-test-2023.run.gz">Top 100 Test BM25 Simple</a></td>
            <td style="text-align: right"> 3.9 MB (1.1 MB compressed)</td>
            <td style="text-align: right">75,696</td>
            <td style="text-align: right">BM25 top 1000 For Test Queries</td>
            <td>tsv: qid, doc_id, rank, score, run-name</td>
          </tr>
        </tbody>
      </table>
      <h2 id="submission-evaluation-and-judging">Submission, evaluation and judging</h2>
      <p>We will be following the classic TREC submission formating, which is repeated below. White space is used to separate columns. The width of the columns in the format is not important, but it is important to have exactly six columns per line with at least one space between the columns.</p>
      <p>, where:</p>
      <div class="language-text highlighter-rouge">
          <div class="highlight">
	      <pre class="highlight">
                  <code>
		      1 Q0 pid1    1 2.73 runid1
		      1 Q0 pid2    1 2.71 runid1
		      1 Q0 pid3    1 2.61 runid1
		      1 Q0 pid4    1 2.05 runid1
		      1 Q0 pid5    1 1.89 runid1
      	          </code>
	      </pre>
	  </div>
      </div>
      <ul>
        <li>the first column is the topic (query) number.</li>
        <li>the second column is currently unused and should always be “Q0”.</li>
        <li>the third column is the official identifier of the retrieved passage in context of passage ranking task, and the identifier of the retrieved document in context of document ranking task.</li>
        <li>the fourth column is the rank the passage/document is retrieved.</li>
        <li>the fifth column shows the score (integer or floating point) that generated the ranking. This score <strong>must</strong> be in descending (non-increasing) order.</li>
        <li>The sixth column is the ID of the run you are submitting.</li>
      </ul>
      <p>As the official evaluation set, we provide a set of 926 queries where 50 or more will be judged by NIST assessors. For this purpose, NIST will be using depth pooling with separate pools each tasks. Products in these pools will then be labelled by NIST assessors using multi-graded judgments, allowing us to measure NDCG.</p>
      <p>The main type of TREC submission is <em>automatic</em>, which means there was not manual intervention in running the test queries. This means you should not adjust your runs, rewrite the query, retrain your model, or make any other sorts of manual adjustments after you see the test queries. The ideal case is that you only look at the test queries to check that they ran properly (i.e. no bugs) then you submit your automatic runs. However, if you want to have a human in the loop for your run, or do anything else that uses the test queries to adjust your model or ranking, you can mark your run as <em>manual</em> and provide a description of what types of alterations were performed. </p>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
  </body>
</html>
